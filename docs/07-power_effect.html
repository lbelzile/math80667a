<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.21">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Experimental design and statistical methods – 7&nbsp; Effect sizes and power</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./08-reproducibility_crisis.html" rel="next">
<link href="./06-blocking_ancova.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./07-power_effect.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Effect sizes and power</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Experimental design and statistical methods</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/lbelzile/math80667a/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./MATH80667A-EDSM.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-hypothesis_testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Hypothesis testing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-completely_randomized_trials.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Completely randomized designs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-contrasts_multipletesting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Contrasts and multiple testing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-interactions_multiway.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Multiway factorial designs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-blocking_ancova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Designs to reduce the error</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-power_effect.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Effect sizes and power</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-reproducibility_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Replication crisis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-repeated.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Repeated measures and multivariate models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-mixed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Introduction to mixed models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-causal-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Causal inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-nonparametric.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Nonparametric tests</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#effect-sizes" id="toc-effect-sizes" class="nav-link active" data-scroll-target="#effect-sizes"><span class="header-section-number">7.1</span> Effect sizes</a>
  <ul class="collapse">
  <li><a href="#standardized-mean-differences" id="toc-standardized-mean-differences" class="nav-link" data-scroll-target="#standardized-mean-differences"><span class="header-section-number">7.1.1</span> Standardized mean differences</a></li>
  <li><a href="#ratio-and-proportion-of-variance" id="toc-ratio-and-proportion-of-variance" class="nav-link" data-scroll-target="#ratio-and-proportion-of-variance"><span class="header-section-number">7.1.2</span> Ratio and proportion of variance</a></li>
  <li><a href="#partial-effects-and-variance-decomposition" id="toc-partial-effects-and-variance-decomposition" class="nav-link" data-scroll-target="#partial-effects-and-variance-decomposition"><span class="header-section-number">7.1.3</span> Partial effects and variance decomposition</a></li>
  </ul></li>
  <li><a href="#power" id="toc-power" class="nav-link" data-scroll-target="#power"><span class="header-section-number">7.2</span> Power</a>
  <ul class="collapse">
  <li><a href="#sec-power-oneway" id="toc-sec-power-oneway" class="nav-link" data-scroll-target="#sec-power-oneway"><span class="header-section-number">7.2.1</span> Power for one-way ANOVA</a></li>
  <li><a href="#power-calculations" id="toc-power-calculations" class="nav-link" data-scroll-target="#power-calculations"><span class="header-section-number">7.2.2</span> Power calculations</a></li>
  <li><a href="#power-in-complex-designs" id="toc-power-in-complex-designs" class="nav-link" data-scroll-target="#power-in-complex-designs"><span class="header-section-number">7.2.3</span> Power in complex designs</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/lbelzile/math80667a/edit/main/07-power_effect.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header">
<h1 class="title display-7"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Effect sizes and power</span></h1>

</header>


<p>In social studies, it is common to write a paper containing multiple studies on a similar topic. These may use different designs, with varying sample size. If the studies uses different questionnaires, or change the Likert scale, the results and the mean difference between groups are not directly comparable between experiments.</p>
<p>We may also wish replicate a study by using the same material and re-run an experiment. For the replication to be somewhat successful (or at least reliable), one needs to determine beforehand how many participants should be recruited in the study.</p>
<p>We could think for an example of comparing statistics or <span class="math inline">\(p\)</span>-values, which are by construction standardized unit less measures, making them comparable across study. Test statistics show how outlying observed differences between experimental conditions relative to a null hypothesis, typically that of no effect (equal mean in each subgroup). However, statistics are usually a function of both the sample size (the number of observations in each experimental condition) and the effect size (how large the standardized differences between groups are), making them unsuitable for describing differences.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-effectsize" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-effectsize-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-power_effect_files/figure-html/fig-effectsize-1.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-effectsize-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1: True sampling distribution for a two-sample <span class="math inline">\(t\)</span>-test under the alternative (rightmost curve) and null distribution (leftmost curve) with small (left panel) and large (right panel) sample sizes.
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-effectsize" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-effectsize</span></a> shows an example with the sampling distributions of the difference in mean under the null (curve centered at zero) and the true alternative (mean difference of two). The area in white under the curve represents the power, which is larger with larger sample size and coincides with smaller average <span class="math inline">\(p\)</span>-values for the testing procedure.</p>
<p>One could argue that, on the surface, every null hypothesis is wrong and that, with a sufficiently large number of observation, all observed differences eventually become “statistically significant”. This has to do with the fact that we become more and more certain of the estimated means of each experimental sub-condition. Statistical significance of a testing procedure does not translate into practical relevance, which itself depends on the scientific question at hand. For example, consider the development of a new drug for commercialization by Health Canada: what is the minimum difference between two treatments that would be large enough to justify commercialization of the new drug? If the effect is small but it leads to many lives saved, would it still be relevant? Such decision involve a trade-off between efficacy of new treatment relative to the status quo, the cost of the drug, the magnitude of the improvement, etc.</p>
<p>Effect size are summaries to inform about the standardized magnitude of these differences; they are used to combine results of multiple experiments using meta-analysis, or to calculate sample size requirements to replicate an effect in power studies.</p>
<section id="effect-sizes" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="effect-sizes"><span class="header-section-number">7.1</span> Effect sizes</h2>
<p>There are two main classes of effect size: standardized mean differences and ratio (percentages) of explained variance. The latter are used in analysis of variance when there are multiple groups to compare.</p>
<p>Unfortunately, the literature on effect size is quite large. Researchers often fail to distinguish between estimand (unknown target) and the estimator that is being used, with frequent notational confusion arising due to conflicting standards and definitions. Terms are also overloaded: the same notation may be used to denote an effect size, but it will be calculated differently depending on whether the design is between-subject or within-subject (with repeated correlated measures per participant), or whether there are blocking factors.</p>
<section id="standardized-mean-differences" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="standardized-mean-differences"><span class="header-section-number">7.1.1</span> Standardized mean differences</h3>
<p>To gather intuition, we begin with the task of comparing the means of two groups using a two-sample <span class="math inline">\(t\)</span>-test, with the null hypothesis of equality in means or <span class="math inline">\(\mathscr{H}_0: \mu_1 = \mu_2\)</span>. The test statistic is <span class="math display">\[\begin{align*}
T =  \frac{\widehat{\mu}_2 - \widehat{\mu}_1}{\widehat{\sigma}} \left(\frac{1}{n_1}+\frac{1}{n_2}\right)^{-1/2}
\end{align*}\]</span> where <span class="math inline">\(\widehat{\sigma}\)</span> is the pooled sample size estimator. The first term, <span class="math inline">\(\widehat{d}_s = (\widehat{\mu}_2 - \widehat{\mu}_1)/\widehat{\sigma}\)</span>, is termed Cohen’s <span class="math inline">\(d\)</span> <span class="citation" data-cites="Cohen:1988">(<a href="#ref-Cohen:1988" role="doc-biblioref">Cohen 1988</a>)</span> and it measures the standardized difference between groups, a form of signal-to-noise ratio. As the sample size gets larger and larger, the sample mean and pooled sample variance become closer and closer to the true population values <span class="math inline">\(\mu_1\)</span>, <span class="math inline">\(\mu_2\)</span> and <span class="math inline">\(\sigma\)</span>; at the same time, the statistic <span class="math inline">\(T\)</span> becomes bigger as <span class="math inline">\(n\)</span> becomes larger because of the second term.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>The difference <span class="math inline">\(d=(\mu_1-\mu_2)/\sigma\)</span> has an obvious interpretation: a distance of <span class="math inline">\(a\)</span> indicates that the means of the two groups are <span class="math inline">\(a\)</span> standard deviation apart. Cohen’s <span class="math inline">\(d\)</span> is sometimes loosely categorized in terms of weak (<span class="math inline">\(d = 0.2\)</span>), medium (<span class="math inline">\(d=0.5\)</span>) and large (<span class="math inline">\(d=0.8\)</span>) effect size; these, much like arbitrary <span class="math inline">\(p\)</span>-value cutoffs, are rules of thumbs. Alongside <span class="math inline">\(d\)</span>, there are many commonly reported metrics that are simple transformations of <span class="math inline">\(d\)</span> describing the observed difference. This interactive <a href="https://rpsychologist.com/cohend/">applet</a> by Kristoffer Magnusson <span class="citation" data-cites="magnussonCohend">(<a href="#ref-magnussonCohend" role="doc-biblioref">Magnusson 2021</a>)</span> shows the visual impact of changing the value of <span class="math inline">\(d\)</span> along. There are different estimators of <span class="math inline">\(d\)</span> depending on whether or not the pooled variance estimator is used. Cohen’s <span class="math inline">\(d\)</span>, is upward biased, meaning it gives values that are on average larger than the truth. Hedge’s <span class="math inline">\(g\)</span> <span class="citation" data-cites="Hedges:1981">(<a href="#ref-Hedges:1981" role="doc-biblioref">Hedges 1981</a>)</span> offers a bias-correction and should always be preferred as an estimator.</p>
<p>For these different estimators, it is possible to obtain (asymmetric) confidence intervals or tolerance intervals.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<div id="exm-LiuRimMinMin2023E1effect" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.1 (Effect sizes for “The Surprise of Reaching Out”)</strong></span> We consider a two-sample <span class="math inline">\(t\)</span>-test for the study of <span class="citation" data-cites="Liu.Rim.Min.Min:2023">Liu et al. (<a href="#ref-Liu.Rim.Min.Min:2023" role="doc-biblioref">2023</a>)</span> discussed in <a href="#exm-LiuRimMinMin2023E1" class="quarto-xref">Example&nbsp;<span class="quarto-unresolved-ref">exm-LiuRimMinMin2023E1</span></a>. The difference in average response index is 0.371, indicating that the responder have a higher score. The <span class="math inline">\(p\)</span>-value is 0.041, showing a small effect.</p>
<p>If we consider the standardized difference <span class="math inline">\(d\)</span>, the group means are -0.289 standard deviations apart based on Hedge’s <span class="math inline">\(g\)</span>, with an associated 95% confidence interval of [-0.567, -0.011]: thus, the difference found is small (using <span class="citation" data-cites="Cohen:1988">Cohen (<a href="#ref-Cohen:1988" role="doc-biblioref">1988</a>)</span>’s convention) and there is a large uncertainty surrounding it.</p>
<p>There is a <span class="math inline">\(42\)</span>% probability that an observation drawn at random from the responder condition will exceed an observation drawn at random of the initiator group (probability of superiority) and <span class="math inline">\(38.6\)</span>% of the responder observations will exceed the median of the initiator (Cohen’s <span class="math inline">\(U_3\)</span>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(LRMM23_S1, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>ttest <span class="ot">&lt;-</span> <span class="fu">t.test</span>(</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  appreciation <span class="sc">~</span> role, </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> LRMM23_S1,</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">var.equal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>effect <span class="ot">&lt;-</span> effectsize<span class="sc">::</span><span class="fu">hedges_g</span>(</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  appreciation <span class="sc">~</span> role, </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> LRMM23_S1, </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">pooled_sd =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="ratio-and-proportion-of-variance" class="level3" data-number="7.1.2">
<h3 data-number="7.1.2" class="anchored" data-anchor-id="ratio-and-proportion-of-variance"><span class="header-section-number">7.1.2</span> Ratio and proportion of variance</h3>
<p>Another class of effect sizes are obtained by considering either the ratio of the variance due to an effect (say differences in means relative to the overall mean) relative to the background level of noise as measured by the variance.</p>
<p>One common measure employed in software is Cohen’s <em>f</em> <span class="citation" data-cites="Cohen:1988">(<a href="#ref-Cohen:1988" role="doc-biblioref">Cohen 1988</a>)</span>, which for a one-way ANOVA (equal variance <span class="math inline">\(\sigma^2\)</span>) with more than two groups, <span class="math display">\[
f^2 = \frac{1}{\sigma^2} \sum_{j=1}^k \frac{n_j}{n}(\mu_j - \mu)^2 = \frac{\sigma^2_{\text{effect}}}{\sigma^2},
\]</span> a weighted sum of squared difference relative to the overall mean <span class="math inline">\(\mu\)</span>. <span class="math inline">\(\sigma^2_{\text{effect}}\)</span> is a measure of the variability that is due to the difference in mean, so standardizing it by the measurement variance gives us a ratio of variance with values higher than one indicating that more variability is explainable, leading to higher effect sizes. If the means of every subgroup is the same, then <span class="math inline">\(f=0\)</span>. For <span class="math inline">\(k=2\)</span> groups, Cohen’s <span class="math inline">\(f\)</span> and Cohen’s <span class="math inline">\(d\)</span> are related via <span class="math inline">\(f=d/2\)</span>.</p>
<p>Cohen’s <span class="math inline">\(f\)</span> can be directly related to the behaviour of the <span class="math inline">\(F\)</span> statistic under an alternative, as explained in <a href="#sec-power-oneway" class="quarto-xref"><span class="quarto-unresolved-ref">sec-power-oneway</span></a>. However, since the interpretation isn’t straightforward, we typically consider proportions of variance (rather than ratios of variance).</p>
<p>To build such an effect size, we break down the variability that is explained by our experimental manipulation (<span class="math inline">\(\sigma^2_\text{effect}\)</span>), here denoted by effect, from the leftover unexplained part, or residual (<span class="math inline">\(\sigma^2_\text{resid}\)</span>). In a one-way analysis of variance, <span class="math display">\[\sigma^2_{\text{total}} = \sigma^2_{\text{resid}} + \sigma^2_{\text{effect}}\]</span> and the percentage of variability explained by the <span class="math inline">\(\text{effect}\)</span>. <span class="math display">\[\eta^2 = \frac{\text{explained variability}}{\text{total variability}}= \frac{\sigma^2_{\text{effect}}}{\sigma^2_{\text{resid}} + \sigma^2_{\text{effect}}} = \frac{\sigma^2_{\text{effect}}}{\sigma^2_{\text{total}}}.\]</span> Simple arithmetic manipulations reveal that <span class="math inline">\(f^2 = \eta^2/(1-\eta^2)\)</span>, so we can relate any proportion of variance in terms of ratio and vice-versa.</p>
<p>Such an effect size depends on unknown population quantities (the true means of each subgroup, the overall mean and the variance). There are multiple alternative estimators to estimate <span class="math inline">\(\eta^2\)</span>, and researchers are often carefree when reporting as to which is used. To disambiguate, I will put <span class="math inline">\(\hat{\eta}^2\)</span> to denote an estimator. To make an analogy, there are many different recipes (estimators) that can lead to a particular cake, but some may lead to a mixing that is on average too wet if they are not well calibrated.</p>
<p>The default estimator for <span class="math inline">\(\eta^2\)</span> is the coefficient of determination of the linear regression, denoted <span class="math inline">\(\widehat{R}^2\)</span> or <span class="math inline">\(\widehat{\eta}^2\)</span>. The latter can be reconstructed from the analysis of variance table using the formula <span class="math display">\[
\widehat{R}{}^2 = \frac{F\nu_1}{F\nu_1 + \nu_2}
\]</span> where for the one-way ANOVA <span class="math inline">\(\nu_1 = K-1\)</span> and <span class="math inline">\(\nu_2 = n-K\)</span> are the degrees of freedom of a design with <span class="math inline">\(n\)</span> observations and <span class="math inline">\(K\)</span> experimental conditions.</p>
<p>Unfortunately, <span class="math inline">\(\widehat{R}{}^2\)</span> is an upward biased estimator (too large on average), leading to optimistic measures. Another estimator of <span class="math inline">\(\eta^2\)</span> that is recommended in <span class="citation" data-cites="Keppel/Wickens:2004">Keppel and Wickens (<a href="#ref-Keppel/Wickens:2004" role="doc-biblioref">2004</a>)</span> for power calculations is <span class="math inline">\(\widehat{\omega}^2\)</span>, which is <span class="math display">\[\widehat{\omega}^2 = \frac{\nu_1 (F-1)}{\nu_1(F-1)+n}.\]</span> Since the <span class="math inline">\(F\)</span> statistic is approximately 1 on average, this measure removes the mode. Both <span class="math inline">\(\widehat{\omega}^2\)</span> and <span class="math inline">\(\widehat{\epsilon}^2\)</span> have been reported to be less biased and thus preferable as estimators of the true proportion of variance <span class="citation" data-cites="Lakens:2013">(<a href="#ref-Lakens:2013" role="doc-biblioref">Lakens 2013</a>)</span>.</p>
<div id="exm-calculation-effect-anova" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.2 (Computing effect size for a between-subject one-way ANOVA)</strong></span> Consider the one-way analysis of variance model for the “Degrees of Reading Power” cloze test, from <span class="citation" data-cites="Baumann:1992">Baumann, Seifert-Kessell, and Jones (<a href="#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span>. The response records the number of correctly answered items, ranging from 0 to 56.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(BSJ92, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit ANOVA model</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>mod_post <span class="ot">&lt;-</span> <span class="fu">lm</span>(posttest3 <span class="sc">~</span> group, <span class="at">data =</span> BSJ92)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract in data frame format the ANOVA table</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>anova_table <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">tidy</span>(<span class="fu">anova</span>(mod_post))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>Fstat <span class="ot">&lt;-</span> anova_table<span class="sc">$</span>statistic[<span class="dv">1</span>]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>dfs <span class="ot">&lt;-</span> anova_table<span class="sc">$</span>df</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Output estimated value of eta-squared</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>(eta_sq <span class="ot">&lt;-</span> Fstat <span class="sc">*</span> dfs[<span class="dv">1</span>] <span class="sc">/</span> (Fstat <span class="sc">*</span> dfs[<span class="dv">1</span>] <span class="sc">+</span> dfs[<span class="dv">2</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1245399</code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare with coefficient of determination from regression</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_post)<span class="sc">$</span>r.squared</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1245399</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare with output from R package 'effectsize'</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>effectsize<span class="sc">::</span><span class="fu">eta_squared</span>(mod_post)<span class="sc">$</span>Eta2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1245399</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare with omega-squared value - the latter is smaller</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>(omega_sq <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="dv">0</span>, dfs[<span class="dv">1</span>]<span class="sc">*</span>(Fstat<span class="dv">-1</span>)<span class="sc">/</span> (dfs[<span class="dv">1</span>]<span class="sc">*</span>(Fstat<span class="dv">-1</span>) <span class="sc">+</span> <span class="fu">nobs</span>(mod_post))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0954215</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>effectsize<span class="sc">::</span><span class="fu">omega_squared</span>(mod_post)<span class="sc">$</span>Omega2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0954215</code></pre>
</div>
</div>
<p>We can also compute effect size for contrasts. Since these take individuall the form of <span class="math inline">\(t\)</span>-tests, we can use <code>emmeans</code> to obtain corresponding effect sizes, which are Cohen’s <span class="math inline">\(d\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>emmeans<span class="sc">::</span><span class="fu">emmeans</span>(mod_post, <span class="at">specs =</span> <span class="st">"group"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  emmeans<span class="sc">::</span><span class="fu">contrast</span>(<span class="fu">list</span>(<span class="at">C1 =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">C2 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>))) <span class="sc">|&gt;</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify estimated std. deviation of data and degrees of freedom </span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  emmeans<span class="sc">::</span><span class="fu">eff_size</span>(<span class="at">sigma =</span> <span class="fu">sigma</span>(mod_post), <span class="at">edf =</span> dfs[<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> contrast effect.size  SE df lower.CL upper.CL
 C1 - C2        0.317 0.4 63   -0.482     1.12

sigma used for effect sizes: 6.314 
Confidence level used: 0.95 </code></pre>
</div>
</div>
</div>
</section>
<section id="partial-effects-and-variance-decomposition" class="level3" data-number="7.1.3">
<h3 data-number="7.1.3" class="anchored" data-anchor-id="partial-effects-and-variance-decomposition"><span class="header-section-number">7.1.3</span> Partial effects and variance decomposition</h3>
<p>In a multiway design with several factors, we may want to estimate the effect of separate factors or interactions. In such cases, we can break down the variability explained by manipulations per effect. The effect size for such models are build by comparing the variance explained by the effect <span class="math inline">\(\sigma^2_{\text{effect}}\)</span>.</p>
<p>For example, say we have a completely randomized balanced design with two factors <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span> and their interaction <span class="math inline">\(AB\)</span>. We can decompose the total variance as <span class="math display">\[\sigma^2_{\text{total}} = \sigma^2_A + \sigma^2_B + \sigma^2_{AB} + \sigma^2_{\text{resid}}.\]</span> When the design is balanced, these variance terms can be estimated using the mean squared error from the analysis of variance table output. If the design is unbalanced, the sum of square decomposition is not unique and we will get different estimates when using Type II and Type III sum of squares.</p>
<p>We can get formula similar to the one-sample case with now what are termed <strong>partial</strong> effect sizes, e.g., <span class="math display">\[\widehat{\omega}^2_{\langle \text{effect} \rangle} = \frac{\text{df}_{\text{effect}}(F_{\text{effect}}-1)}{\text{df}_{\text{effect}}(F_{\text{effect}}-1) + n},\]</span> where <span class="math inline">\(n\)</span> is the overall sample size and <span class="math inline">\(F_\text{effect}\)</span> and the corresponding degrees of freedom could be the statistic associated to the main effects <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, or the interaction term <span class="math inline">\(AB\)</span>. In <strong>R</strong>, the <code>effectsize</code> package reports these estimates with one-sided confidence intervals derived using the pivot method <span class="citation" data-cites="Steiger:2004">(<a href="#ref-Steiger:2004" role="doc-biblioref">Steiger 2004</a>)</span>.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>Software will typically return estimates of effect size alongside with the designs, but there are small things to keep in mind. One is that the decomposition of the variance is not unique with unbalanced data. The second is that, when using repeated measures and mixed models, the same notation is used to denote different quantities.</p>
<p>Lastly, it is customary to report effect sizes that include the variability of blocking factors and random effects, leading to so-called <strong>generalized</strong> effect sizes. Include the variance of all blocking factors and interactions (only with the effect!) in the denominator.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>For example, if <span class="math inline">\(A\)</span> is the experimental factor whose main effect is of interest, <span class="math inline">\(B\)</span> is a blocking factor and <span class="math inline">\(C\)</span> is another experimental factor, use <span class="math display">\[\eta_{\langle A \rangle}^2 = \frac{\sigma^2_A}{\sigma^2_A + \sigma^2_B + \sigma^2_{AB} + \sigma^2_{\text{resid}}}.\]</span> as generalized partial effect. The reason for including blocking factors and random effects is that they would not necessarily be available in a replication. The correct effect size measure to calculate and to report depends on the design, and there are numerous estimators that can be utilized. Since they are related to one another, it is oftentimes possible to compute them directly from the output or convert. The formula highlight the importance of reporting (with enough precision) exactly the values of the test statistic.</p>
<div id="exm-blocking" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.3</strong></span> In <strong>R</strong>, the <code>effectsize</code> package functions, which are displayed prominently in this chapter, have a <code>generalized</code> argument to which the vector of names of blocking factor can be passed. We use the one-way analysis of variance from <a href="#exm-reachingout" class="quarto-xref">Example&nbsp;<span class="quarto-unresolved-ref">exm-reachingout</span></a> for illustrating the calculation. Once again, the output matches the output of the package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>mod_block <span class="ot">&lt;-</span> <span class="fu">lm</span>(apprec <span class="sc">~</span> role <span class="sc">+</span> dyad, <span class="at">data =</span> LRMM23_S3l)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>anova_tab <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">tidy</span>(<span class="fu">anova</span>(mod_block))</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the generalized effect size - variance are estimated</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># based on sum of squared termes in the ANOVA table</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(anova_tab, sumsq[<span class="dv">1</span>]<span class="sc">/</span><span class="fu">sum</span>(sumsq))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.08802785</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We can use the 'effectsize' package, specifying the blocking factor</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># through argument 'generalized'</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>eff <span class="ot">&lt;-</span> effectsize<span class="sc">::</span><span class="fu">eta_squared</span>(<span class="at">model =</span> mod_block, <span class="at">generalized =</span> <span class="st">"dyad"</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the generalized eta-squared effect size for 'role' for comparison</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>eff<span class="sc">$</span>Eta2_generalized[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.08802785</code></pre>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pitfall
</div>
</div>
<div class="callout-body-container callout-body">
<p>Measures of effect size are estimated based on data, but unlike summary statistics such as the mean and variance, tend to be very noisy in small samples and the uncertainty remains significant for larger samples. To show this, I simulated datasets for a two sample <span class="math inline">\(t\)</span>-test: there is no effect for the control group, but the true effect for the treatment group is <span class="math inline">\(d=0.2\)</span>. With balanced data (<span class="math inline">\(n/2\)</span> observations in each group) power is maximised. <a href="#fig-effectsizedispersion" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-effectsizedispersion</span></a> shows the estimated sample size for <span class="math inline">\(B=100\)</span> replications of the experiment at samples of size <span class="math inline">\(n=10, 12, \ldots, 250\)</span>. The horizontal lines at <span class="math inline">\(0\)</span> represent no effect: the proportion of values which show effects that are of opposite sign to the truth is still significant at <span class="math inline">\(n=250\)</span> observations, and the variability seems to decrease very slowly. For smaller samples, the effect sizes are erratic and, although they are centered at the true value, most of them are severely inflated.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-effectsizedispersion" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-effectsizedispersion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-power_effect_files/figure-html/fig-effectsizedispersion-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-effectsizedispersion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2: Dispersion of estimated effect size for data with a true mean dispersion of <span class="math inline">\(d=0.2\)</span>, for different sample size.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="power" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="power"><span class="header-section-number">7.2</span> Power</h2>
<p>There are typically two uses to hypothesis test: either we want to show it is not unreasonable to assume the null hypothesis (for example, assuming equal variance), or else we want to show beyond reasonable doubt that a difference or effect is significative: for example, one could wish to demonstrate that a new website design (alternative hypothesis) leads to a significant increase in sales relative to the status quo (null hypothesis).</p>
<p>Our ability make discoveries depends on the power of the test: the larger the power, the greater our ability to reject the null hypothesis <span class="math inline">\(\mathscr{H}_0\)</span> when the latter is false.</p>
<p>The <strong>power of a test</strong> is the probability of <strong>correctly</strong> rejecting the null hypothesis <span class="math inline">\(\mathscr{H}_0\)</span> when <span class="math inline">\(\mathscr{H}_0\)</span> is false, i.e., <span class="math display">\[\begin{align*}
\mathsf{Pr}_a(\text{reject} \mathscr{H}_0)
\end{align*}\]</span> Whereas the null alternative corresponds to a single value (equality in mean), there are infinitely many alternatives… Depending on the alternative models, it is more or less easy to detect that the null hypothesis is false and reject in favour of an alternative. Power is thus a measure of our ability to detect real effects. Different test statistics can give broadly similar conclusions despite being based on different benchmark. Generally, however, there will be a tradeoff between the number of assumptions we make about our data or model (the fewer, the better) and the ability to draw conclusions when there is truly something going on when the null hypothesis is false.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-power1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-power1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-power_effect_files/figure-html/fig-power1-1.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-power1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.3: Comparison between null distribution (full curve) and a specific alternative for a <em>t</em>-test (dashed line). The power corresponds to the area under the curve of the density of the alternative distribution which is in the rejection area (in white).
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-power2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-power2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-power_effect_files/figure-html/fig-power2-1.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-power2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.4: Increase in power due to an increase in the mean difference between the null and alternative hypothesis. Power is the area in the rejection region (in white) under the alternative distribution (dashed): the latter is more shifted to the right relative to the null distribution (full line).
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-power3" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-power3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-power_effect_files/figure-html/fig-power3-1.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-power3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.5: Increase of power due to an increase in the sample size or a decrease of standard deviation of the population: the null distribution (full line) is more concentrated. Power is given by the area (white) under the curve of the alternative distribution (dashed). In general, the null distribution changes with the sample size.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We want to choose an experimental design and a test statistic that leads to high power, so that this power is as close as possible to one. Under various assumptions about the distribution of the original data, we can derive optimal tests that are most powerful, but some of the power comes from imposing more structure and these assumptions need not be satisfied in practice.</p>
<p>Minimally, the power of the test should be <span class="math inline">\(\alpha\)</span> because we reject the null hypothesis <span class="math inline">\(\alpha\)</span> fraction of the time even when <span class="math inline">\(\mathscr{H}_0\)</span> is true. Power depends on many criteria, notably</p>
<ul>
<li>the effect size: the bigger the difference between the postulated value for <span class="math inline">\(\theta_0\)</span> under <span class="math inline">\(\mathscr{H}_0\)</span> and the observed behaviour, the easier it is to detect departures from <span class="math inline">\(\theta_0\)</span>. (<a href="#fig-power3" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-power3</span></a>); it’s easier to spot an elephant in a room than a mouse.</li>
<li>variability: the less noisy your data, the easier it is to assess that the observed differences are genuine, as <a href="#fig-power2" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-power2</span></a> shows;</li>
<li>the sample size: the more observation, the higher our ability to detect significative differences because the amount of evidence increases as we gather more observations.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> In experimental designs, the power also depends on how many observations are allocated to each group.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></li>
<li>the choice of test statistic: there is a plethora of possible statistics to choose from as a summary of the evidence against the null hypothesis. Choosing and designing statistics is usually best left out to statisticians, as there may be tradeoffs. For example, rank-based statistics discard information about the observed values of the response, focusing instead on their relative ranking. The resulting tests are typically less powerful, but they are also less sensible to model assumptions, model misspecification and outliers.</li>
</ul>
<p>Changing the value of <span class="math inline">\(\alpha\)</span> also has an impact on the power, since larger values of <span class="math inline">\(\alpha\)</span> move the cutoff towards the bulk of the distribution. However, it entails a higher percentage of rejection also when the alternative is false. Since the value of <span class="math inline">\(\alpha\)</span> is fixed beforehand to control the type I error (avoid judicial mistakes), it’s not a parameter we consider.</p>
<p>There is an intricate relation between effect size, power and sample size. Journals and grant agencies oftentimes require an estimate of the latter before funding a study, so one needs to ensure that the sample size is large enough to pick-up effects of scientific interest (good signal-to-noise), but also not overly large as to minimize time and money and make an efficient allocation of resources. This is Goldilock’s principle, but having more never hurts.</p>
<p>If we run a pilot study to estimate the background level of noise and the estimated effect, or if we wish to perform a replication study, we will come up with a similar question in both cases: how many participants are needed to reliably detect such a difference? Setting a minimum value for the power (at least 80%, but typically 90% or 95% when feasible) ensures that the study is more reliable and ensures a high chance of success of finding an effect of at least the size specified. A power of 80% ensures that, on average, 4 in 5 experiments in which we study a phenomenon with the specified non-null effect size should lead to rejecting the null hypothesis.</p>
<p>In order to better understand the interplay between power, effect size and sample size, we consider a theoretical example. The purpose of displaying the formula is to (hopefully) more transparently confirm some of our intuitions about what leads to higher power. There are many things that can influence the power:</p>
<ul>
<li>the experimental design: a blocking design or repeated measures tend to filter out some of the unwanted variability in the population, thus increasing power relative to a completely randomized design</li>
<li>the background variability <span class="math inline">\(\sigma\)</span>: the noise level is oftentimes intrinsic to the measurement. It depends on the phenomenon under study, but instrumentation and the choice of scale, etc. can have an impact. Running experiments in a controlled environment helps reduce this, but researchers typically have limited control on the variability inherent to each observation.</li>
<li>the sample size: as more data are gathered, information accumulates. The precision of measurements (e.g., differences in mean) is normally determined by the group with the smallest sample size, so (approximate) balancing increases power if the variance in each group is the same.</li>
<li>the size of the effect: the bigger the effect, the easier it is to accurately detect (it’s easier to spot an elephant than a mouse hiding in a classroom).</li>
<li>the level of the test, <span class="math inline">\(\alpha\)</span>: if we increase the rejection region, we technically increase power when we run an experiment under an alternative regime. However, the level is oftentimes prespecified to avoid type I errors. We may consider multiplicity correction within the power function, such as Bonferonni’s method, which is equivalent to reducing <span class="math inline">\(\alpha\)</span>.</li>
</ul>
<section id="sec-power-oneway" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="sec-power-oneway"><span class="header-section-number">7.2.1</span> Power for one-way ANOVA</h3>
<p>To fix ideas, we consider the one-way analysis of variance model. In the usual setup, we consider <span class="math inline">\(K\)</span> experimental conditions with <span class="math inline">\(n_k\)</span> observations in group <span class="math inline">\(k\)</span>, whose population average we denote by <span class="math inline">\(\mu_k\)</span>. We can parametrize the model in terms of the overall sample average, <span class="math display">\[\begin{align*}
\mu = \frac{1}{n}\sum_{j=1}^K\sum_{i=1}^{n_j} \mu_j = \frac{1}{n}\sum_{j=1}^K n_j \mu_j,
\end{align*}\]</span> where <span class="math inline">\(n=n_1 + \cdots +n_K\)</span> is the total sample size. The <span class="math inline">\(F\)</span>-statistic of the one-way ANOVA is <span class="math display">\[\begin{align*}
F =  \frac{\text{between sum of squares}/(K-1)}{\text{within sum of squares}/(n-K)}
\end{align*}\]</span> The null distribution is <span class="math inline">\(F(K-1, n-K)\)</span>. Our interest is in understanding how the <em>F</em>-statistic behaves under an alternative.</p>
<p>During the construction, we stressed out that the denominator is an estimator of <span class="math inline">\(\sigma^2\)</span> under both the null and alternative. What happens to the numerator? We can write the population average for the between sum of square as <span class="math display">\[
\mathsf{E}(\text{between sum of squares}) = \sigma^2\{(K-1) + \Delta\}.
\]</span> where <span class="math display">\[
\Delta = \dfrac{\sum_{j=1}^K n_j(\mu_j - \mu)^2}{\sigma^2} = nf^2.
\]</span> and where <span class="math inline">\(f^2\)</span> is the square of Cohen’s <span class="math inline">\(f\)</span>. Under the null hypothesis, all group means are equal and <span class="math inline">\(\mu_j=\mu\)</span> for <span class="math inline">\(j=1, \ldots, K\)</span> and <span class="math inline">\(\Delta=0\)</span>, but if some groups have different average the displacement will be non-zero. The greater <span class="math inline">\(\Delta\)</span>, the further the mode (peak of the distribution) is from unity and the greater the power.</p>
<p>Closer examination reveals that <span class="math inline">\(\Delta\)</span> increases with <span class="math inline">\(n_j\)</span> (sample size) and with the true squared mean difference <span class="math inline">\((\mu_j-\mu)^2\)</span> increases effect size represented by the difference in mean, but decreases as the observation variance increases.</p>
<p>Under the alternative, the distribution of the <span class="math inline">\(F\)</span> statistic is a noncentral Fisher distribution, denoted <span class="math inline">\(\mathsf{F}(\nu_1, \nu_2, \Delta)\)</span> with degrees of freedom <span class="math inline">\(\nu_1\)</span> and <span class="math inline">\(\nu_2\)</span> and noncentrality parameter <span class="math inline">\(\Delta\)</span>.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> To calculate the power of a test, we need to single out a specific alternative hypothesis.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-powercurve" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-powercurve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-power_effect_files/figure-html/fig-powercurve-1.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-powercurve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.6: Density curves for the null distribution (full line) and true distribution (dashed line) under noncentrality parameter <span class="math inline">\(\Delta=3\)</span>. The area in white under the curve denotes the power under this alternative.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The plot in <a href="#fig-powercurve" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-powercurve</span></a> shows the null (full line) distribution and the true distribution (dashed line) for a particular alternative. The noncentral <span class="math inline">\(\mathsf{F}\)</span> is shifted to the right and right skewed, so the mode (peak) is further away from 1.</p>
<p>Given a value of <span class="math inline">\(\Delta=nf^2\)</span> and information about the effect of interest (degrees of freedom of the effect and the residuals), we can compute the tail probability as follows</p>
<ol type="1">
<li>Compute the cutoff point: the value under <span class="math inline">\(\mathscr{H}_0\)</span> that leads to rejection at level <span class="math inline">\(\alpha\)</span></li>
<li>Compute probability below the alternative curve, from the cutoff onwards.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>cutoff <span class="ot">&lt;-</span> <span class="fu">qf</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df1 =</span> df1, <span class="at">df2 =</span> df2)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pf</span>(<span class="at">q =</span> cutoff,  <span class="at">df1 =</span> df1, <span class="at">df2 =</span> df2, </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">ncp =</span> Delta, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="power-calculations" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="power-calculations"><span class="header-section-number">7.2.2</span> Power calculations</h3>
<p>In practice, a software will return these quantities and inform us about the power. Note that these results are trustworthy provided the model assumptions are met, otherwise they may be misleading.</p>
<p>The most difficult question when trying to estimate sample size for a study is determining which value to use for the effect size. One could opt for a value reported elsewhere for a similar scale to estimate the variability and provide educated guesses for the mean differences. Another option is to run a pilot study and use the resulting estimates to inform about sensible values, perhaps using confidence intervals to see the range of plausible effect sizes. Keep in mind the findings from <a href="#fig-effectsizedispersion" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-effectsizedispersion</span></a>.</p>
<p>Reliance on estimated effect sizes reported in the literature is debatable: many such effects are inflated as a result of the file-drawer problem and, as such, can lead to unreasonably high expectations about power.</p>
<p>The <code>WebPower</code> package in <strong>R</strong> offers a comprehensive solution for conducting power studies, as does the free software <a href="https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower">G*Power</a>. We present a range of examples from a replication study: the following quotes are taken from the <a href="https://osf.io/ezcuj/">Reproducibility Project: Psychology</a>.</p>
<div id="exm-poweranova1" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.4 (Power calculation for between subject ANOVA)</strong></span> The following extract of <a href="https://osf.io/sd4uv/">Jesse Chandler’s replication</a> concerns Study 4b by <span class="citation" data-cites="Janiszewski.Uy:2008">Janiszewski and Uy (<a href="#ref-Janiszewski.Uy:2008" role="doc-biblioref">2008</a>)</span>, which considers a <span class="math inline">\(2 \times 2\)</span> between-subject ANOVA.</p>
<blockquote class="blockquote">
<p>In Study 4a there are two effects of theoretical interest, a substantial main effect of anchor precision that replicates the first three studies and a small interaction (between precision and motivation within which people can adjust) that is not central to the paper. The main effect of anchor precision (effect size <span class="math inline">\(\eta^2_p=0.55\)</span>) would require a sample size of <span class="math inline">\(10\)</span> for <span class="math inline">\(80\)</span>% power, <span class="math inline">\(12\)</span> for <span class="math inline">\(90\)</span>% power, and <span class="math inline">\(14\)</span> for <span class="math inline">\(95\)</span>% power. The interaction (effect size <span class="math inline">\(\eta^2_p=0.11\)</span>) would require a sample size of <span class="math inline">\(65\)</span> for <span class="math inline">\(80\)</span>% power, <span class="math inline">\(87\)</span> for <span class="math inline">\(90\)</span>% power, and <span class="math inline">\(107\)</span> for <span class="math inline">\(95\)</span>% power. There was also a theoretically uninteresting main effect of motivation (people adjust more when told to adjust more).</p>
</blockquote>
<p>In order to replicate, we must first convert estimates of <span class="math inline">\(\eta^2_p\)</span> to Cohen’s <span class="math inline">\(f\)</span>, which is the input accepted by both <code>WebPower</code> and G*Power. We compute the sample size for power 95% for both the main effect and the interaction: in practice, we would pick the smaller of the two (or equivalently the larger resulting sample size estimate) should we wish to replicate both findings.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> effectsize<span class="sc">::</span><span class="fu">eta2_to_f</span>(<span class="fl">0.55</span>) <span class="co"># convert eta-squared to Cohen's f</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>ng <span class="ot">&lt;-</span> <span class="dv">4</span> <span class="co"># number of groups for the ANOVA</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ceiling</span>(WebPower<span class="sc">::</span><span class="fu">wp.kanova</span>(<span class="at">ndf =</span> <span class="dv">1</span>, <span class="at">ng =</span> ng, <span class="at">f =</span> f, <span class="at">power =</span> <span class="fl">0.95</span>)<span class="sc">$</span>n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> effectsize<span class="sc">::</span><span class="fu">eta2_to_f</span>(<span class="fl">0.11</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ceiling</span>(WebPower<span class="sc">::</span><span class="fu">wp.kanova</span>(<span class="at">ndf =</span> <span class="dv">1</span>, <span class="at">ng =</span> ng, <span class="at">f =</span> f, <span class="at">power =</span> <span class="fl">0.95</span>)<span class="sc">$</span>n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 108</code></pre>
</div>
</div>
<p>We can see that the numbers match the calculations from the replication (up to rounding).</p>
</div>
<div id="exm-power-within" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.5 (Power calculation for mixed design)</strong></span> Repeated measures ANOVA have different characteristics from between-subject design in that measurements are correlated, and we can also provide correction for sphericity. These additional parameters need to specified by users. In <code>WebPower</code>, the <code>wp.rmanova</code> function. We need to specify the number of measurements per person, the number of groups, the value <span class="math inline">\(\epsilon\)</span> for the sphericity correction, e.g., the output of Greenhouse–Geisser or Huynh–Feldt and the type of effect for between-subject factor, within-subject factor or an interaction between the two.</p>
<blockquote class="blockquote">
<p>The result that is object of this replication is the interaction between item strength (massed vs.&nbsp;spaced presentation) and condition (directed forgetting vs.&nbsp;control). The dependent variable is the proportion of correctly remembered items from the stimulus set (List 1). “(..) The interaction was significant, <span class="math inline">\(F(1,94)=4.97\)</span>, <span class="math inline">\(p &lt;.05\)</span>, <span class="math inline">\(\mathrm{MSE} =0.029\)</span>, <span class="math inline">\(\eta^2=0.05\)</span>, (…)”. (p.&nbsp;412). Power analysis (G*Power (Version 3.1): ANOVA: Repeated measures, within-between interaction with a zero correlation between the repeated measures) indicated that sample sizes for <span class="math inline">\(80\)</span>%, <span class="math inline">\(90\)</span>% and <span class="math inline">\(95\)</span>% power were respectively <span class="math inline">\(78\)</span>, <span class="math inline">\(102\)</span> and <span class="math inline">\(126\)</span>.</p>
</blockquote>
<p>We are thus considering a <span class="math inline">\(2 \times 2\)</span> within-between design. The estimated effect size is <span class="math inline">\(\widehat{\eta}^2_p=0.05\)</span>, with Cohen’s <span class="math inline">\(f\)</span>, where the value is multiplied by a constant <span class="math inline">\(C\)</span>; <a href="https://webpower.psychstat.org/wiki/manual/power_of_rmanova">see the WebPower page</a> which depends on the number of groups, the number of repeated measurements <span class="math inline">\(K\)</span> and their correlation <span class="math inline">\(\rho\)</span>. For the interaction, the correction factor is <span class="math inline">\(C = \sqrt{K/(1-\rho)}\)</span>: taking <span class="math inline">\(K=2\)</span> and <span class="math inline">\(\rho=0\)</span>, we get a Cohen’s <span class="math inline">\(f\)</span> of 0.23. We calculate the sample size for a power of 90% changing <span class="math inline">\(\rho\)</span>: if we change the correlation in the calculation from zero to <span class="math inline">\(0.5\)</span>, we can see that there is a significant decrease in the sample size.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> effectsize<span class="sc">::</span><span class="fu">eta2_to_f</span>(<span class="fl">0.05</span>) <span class="co"># convert eta-squared to Cohen's f</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="co"># correlation between measurements</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="dv">2</span>L <span class="co"># number of repeated measurements</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(WebPower<span class="sc">::</span><span class="fu">wp.rmanova</span>(<span class="at">type =</span> <span class="dv">2</span>, <span class="co"># interaction </span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>                           <span class="at">nm =</span> K, <span class="co"># number of measurement per subject</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>                           <span class="at">ng =</span> <span class="dv">2</span>, <span class="co"># number of groups for between,</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>                           <span class="at">f =</span> f<span class="sc">*</span><span class="fu">sqrt</span>(K<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>rho)), <span class="co"># scaled effect size</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>                           <span class="at">power =</span> <span class="fl">0.9</span>)<span class="sc">$</span>n) <span class="co"># requested power</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 102</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-Gpower" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-Gpower-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/GPower.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-Gpower-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.7: Screenshot of G*Power for the calculation of the sample size to replicate the interaction in a repeated measures (within-between) analysis of variance.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-rmanova" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rmanova-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-power_effect_files/figure-html/fig-rmanova-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rmanova-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.8: Sample size requirement for a within-between interaction in a two by two (within-between) ANOVa with an effect size of <span class="math inline">\(\widehat{\eta}^2_p = 0.05\)</span> as a function of correlation and power. The staircase pattern is an artefact of rounding up to the nearest integer.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We can see that the more correlated the response, the smaller sample size requirement according to <a href="#fig-rmanova" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-rmanova</span></a>. Higher power requirement leads to larger data collection efforts.</p>
</div>
<div id="exm-power-ttest" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.6 (Power calculation for a two sample <span class="math inline">\(t\)</span>-test)</strong></span> We consider a two-sample comparison, as these arise frequently from contrasts. The replication wishes to replicate a study whose estimated effect size was a Cohen’s <span class="math inline">\(d\)</span> of <span class="math inline">\(\widehat{d} = 0.451\)</span>. Using a two-tailed test with a balanced sample and <span class="math inline">\(\alpha = 0.05\)</span> type I error rate, we obtain <span class="math inline">\(258\)</span> participants. Note that some software, as below, report the sample size by group so the total sample size is twice the number reported.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">ceiling</span>(WebPower<span class="sc">::</span><span class="fu">wp.t</span>(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">"two.sample"</span>,</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">alternative =</span> <span class="st">"two.sided"</span>,</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">d =</span> <span class="fl">0.451</span>, <span class="co"># Cohen's f</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fl">0.95</span>)<span class="sc">$</span>n) <span class="co"># power requirement</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 258</code></pre>
</div>
</div>
<p>The function also allows us to figure out the effect size one could obtain for given power and fixed sample size, by replacing <code>d</code> with the latter via arguments <code>n1</code> and <code>n2</code>.</p>
</div>
</section>
<section id="power-in-complex-designs" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="power-in-complex-designs"><span class="header-section-number">7.2.3</span> Power in complex designs</h3>
<p>In cases where an analytic derivations isn’t possible, we can resort to simulations to approximate the power. For a given alternative, we</p>
<ul>
<li>simulate repeatedly samples from the model from the hypothetical alternative world</li>
<li>we compute the test statistic for each of these new samples</li>
<li>we transform these to the associated <em>p</em>-values based on the postulated null hypothesis.</li>
</ul>
<p>At the end, we calculate the proportion of tests that lead to a rejection of the null hypothesis at level <span class="math inline">\(\alpha\)</span>, namely the percentage of <em>p</em>-values smaller than <span class="math inline">\(\alpha\)</span>. We can vary the sample size and see how many observations we need per group to achieve the desired level of power.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<strong>Summary</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Effect sizes are used to provide a standardized measure of the strength of a result, independent of the design and the sample size.</li>
<li>There are two classes: standardized differences and proportions of variance.</li>
<li>Multiple estimators exists: report the latter along with the software used to compute confidence intervals.</li>
<li>The adequate measure of variability to use for the effect size depends on the design: we normally include the variability of blocking factors and residual variance.</li>
<li>Given a design, we can deduce either the sample size, the power or the effect size from the other two metrics. This allows us to compute sample size for a study or replication.</li>
</ul>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Baumann:1992" class="csl-entry" role="listitem">
Baumann, James F., Nancy Seifert-Kessell, and Leah A. Jones. 1992. <span>“Effect of Think-Aloud Instruction on Elementary Students’ Comprehension Monitoring Abilities.”</span> <em>Journal of Reading Behavior</em> 24 (2): 143–72. <a href="https://doi.org/10.1080/10862969209547770">https://doi.org/10.1080/10862969209547770</a>.
</div>
<div id="ref-Cohen:1988" class="csl-entry" role="listitem">
Cohen, J. 1988. <em>Statistical Power Analysis for the Behavioral Sciences</em>. 2nd ed. New York: Routledge. <a href="https://doi.org/10.4324/9780203771587">https://doi.org/10.4324/9780203771587</a>.
</div>
<div id="ref-Hedges:1981" class="csl-entry" role="listitem">
Hedges, Larry V. 1981. <span>“Distribution Theory for <span>G</span>lass’s Estimator of Effect Size and Related Estimators.”</span> <em>Journal of Educational Statistics</em> 6 (2): 107–28. <a href="https://doi.org/10.3102/10769986006002107">https://doi.org/10.3102/10769986006002107</a>.
</div>
<div id="ref-Janiszewski.Uy:2008" class="csl-entry" role="listitem">
Janiszewski, Chris, and Dan Uy. 2008. <span>“Precision of the Anchor Influences the Amount of Adjustment.”</span> <em>Psychological Science</em> 19 (2): 121–27. <a href="https://doi.org/10.1111/j.1467-9280.2008.02057.x">https://doi.org/10.1111/j.1467-9280.2008.02057.x</a>.
</div>
<div id="ref-Keppel/Wickens:2004" class="csl-entry" role="listitem">
Keppel, G., and T. D. Wickens. 2004. <em>Design and Analysis: A Researcher’s Handbook</em>. Pearson Prentice Hall.
</div>
<div id="ref-Lakens:2013" class="csl-entry" role="listitem">
Lakens, Daniel. 2013. <span>“Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for <span class="math inline">\(t\)</span>-Tests and ANOVAs.”</span> <em>Frontiers in Psychology</em> 4: 863. <a href="https://doi.org/10.3389/fpsyg.2013.00863">https://doi.org/10.3389/fpsyg.2013.00863</a>.
</div>
<div id="ref-Liu.Rim.Min.Min:2023" class="csl-entry" role="listitem">
Liu, Peggy J., SoYon Rim, Lauren Min, and Kate E. Min. 2023. <span>“The Surprise of Reaching Out: Appreciated More Than We Think.”</span> <em>Journal of Personality and Social Psychology</em> 124 (4): 754–71. <a href="https://doi.org/10.1037/pspi0000402">https://doi.org/10.1037/pspi0000402</a>.
</div>
<div id="ref-magnussonCohend" class="csl-entry" role="listitem">
Magnusson, Kristoffer. 2021. <span>“Interpreting <span>C</span>ohen’s <span class="math inline">\(d\)</span> Effect Size: An Interactive Visualization.”</span> <a href="https://rpsychologist.com/cohend/">https://rpsychologist.com/cohend/</a>.
</div>
<div id="ref-Steiger:2004" class="csl-entry" role="listitem">
Steiger, James H. 2004. <span>“Beyond the <span class="math inline">\(F\)</span> Test: Effect Size Confidence Intervals and Tests of Close Fit in the Analysis of Variance and Contrast Analysis.”</span> <em>Psychological Methods</em> 9: 164–82. <a href="https://doi.org/10.1037/1082-989X.9.2.164">https://doi.org/10.1037/1082-989X.9.2.164</a>.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>If we consider a balanced sample, <span class="math inline">\(n_1 = n_2 = n/2\)</span> we can rewrite the statistic as <span class="math inline">\(T = \sqrt{n} \widehat{d}_s/2\)</span> and the statement that <span class="math inline">\(T\)</span> increases with <span class="math inline">\(n\)</span> on average becomes more obvious.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>By using the pivot method, e.g., <span class="citation" data-cites="Steiger:2004">Steiger (<a href="#ref-Steiger:2004" role="doc-biblioref">2004</a>)</span>, and relating the effect size to the noncentrality parameter of the null distribution, whether <span class="math inline">\(\mathsf{St}\)</span>, <span class="math inline">\(\mathsf{F}\)</span> or <span class="math inline">\(\chi^2\)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The confidence intervals are based on the <span class="math inline">\(\mathsf{F}\)</span> distribution, by changing the non-centrality parameter and inverting the distribution function (pivot method). This yields asymmetric intervals.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Typically, there won’t be any interaction with blocking factors, but it there was for some reason, it should be included in the total.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Specifically, the standard error decreases with sample size <span class="math inline">\(n\)</span> at a rate (typically) of <span class="math inline">\(n^{-1/2}\)</span>. The null distribution also becomes more concentrated as the sample size increase.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>While the default is to assign an equal number to each subgroup, power may be maximized by specifying different sample size in each group if the variability of the measurement differ in these groups.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Note that the <span class="math inline">\(F(\nu_1, \nu_2)\)</span> distribution is indistinguishable from <span class="math inline">\(\chi^2(\nu_1)\)</span> for <span class="math inline">\(\nu_2\)</span> large. A similar result holds for tests with <span class="math inline">\(\chi^2\)</span> null distributions.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/lbelzile\.github\.io\/math80667a\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./06-blocking_ancova.html" class="pagination-link" aria-label="Designs to reduce the error">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Designs to reduce the error</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./08-reproducibility_crisis.html" class="pagination-link" aria-label="Replication crisis">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Replication crisis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/lbelzile/math80667a/edit/main/07-power_effect.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>